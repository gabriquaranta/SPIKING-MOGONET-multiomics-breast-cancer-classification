{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform a Graph Convolutional Network (GCN) into a spiking version, we need to replace the traditional neural network layers with their spiking counterparts. \n",
    "\n",
    "This process involves introducing temporal dynamics and modeling the information propagation using spike trains instead of static activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIF : Leaky Integrate-and-Fire Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace Traditional Neurons with Spiking Neurons**:\n",
    "\n",
    "The first step is to replace the traditional neurons in the GCN layers with spiking neurons. Spiking neurons model the behavior of biological neurons by generating and transmitting spike trains over time, rather than processing static activations.\n",
    "\n",
    "There are various spiking neuron models available, such as Leaky Integrate-and-Fire (LIF), Izhikevich, and Hodgkin-Huxley models. For this example, we'll use the LIF model, which is a widely used and computationally efficient spiking neuron model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA= torch.tensor(0.9)\n",
    "BETA = torch.tensor(0.5)\n",
    "\n",
    "class LIFNeuron(snn.Synaptic):\n",
    "    def __init__(self):\n",
    "        super(LIFNeuron, self).__init__(alpha=ALPHA, beta=BETA)\n",
    "\n",
    "        self.tau_mem = 20.0 # Membrane time constant\n",
    "        self.tau_syn = 5.0 # Synaptic time constant\n",
    "\n",
    "    def set_batch_size(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Update the membrane potential and synaptic current using the input spike train\n",
    "        mem, synaptic_current = self.lif(x, alpha=self.alpha, beta=self.beta, tau_mem=self.tau_mem, tau_syn=self.tau_syn) \n",
    "        return mem, synaptic_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization:\n",
    "\n",
    "- **tau_mem** (membrane time constant): This parameter determines the rate at which the membrane potential decays over time. A higher value means the membrane potential decays more slowly.\n",
    "\n",
    "- **tau_syn** (synaptic time constant): This parameter determines the rate at which the synaptic current decays over time. A higher value means the synaptic current decays more slowly.\n",
    "\n",
    "### Forward Pass:\n",
    "\n",
    "- **x**: This is the input tensor representing the incoming spike trains or synaptic currents.\n",
    "\n",
    "- **mem, synaptic_current = self.lif(x, self.mem, self.synaptic_current)**:\n",
    "\n",
    "    The lif method computes the membrane potential (mem) and synaptic current (synaptic_current) for the current time step, based on the input x and the previous state variables (self.mem and self.synaptic_current).\n",
    "\n",
    "    The lif method implements the dynamics of the LIF neuron model, which can be summarized as follows:\n",
    "\n",
    "    - The membrane potential (mem) is computed by integrating the synaptic current (synaptic_current) with a leaky integration, controlled by the membrane time constant (tau_mem).\n",
    "\n",
    "    - If the membrane potential exceeds a threshold value (typically 1.0), a spike is generated, and the membrane potential is reset to a resting value (typically 0.0).\n",
    "    \n",
    "    - The synaptic current (synaptic_current) is computed by integrating the input (x) with an exponential decay controlled by the synaptic time constant (tau_syn).\n",
    "\n",
    "- **return mem, synaptic_current**: The updated membrane potential (mem) and synaptic current (synaptic_current) are returned as the output of the forward method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LIFNeuron class implements the Leaky Integrate-and-Fire neuron model, which is a spiking neuron model that integrates incoming synaptic currents over time and generates output spikes when the membrane potential exceeds a threshold.\n",
    "\n",
    "The class takes the input spike trains (or synaptic currents) and computes the updated membrane potential and synaptic current based on the LIF dynamics and the specified time constants (tau_mem and tau_syn).\n",
    "\n",
    "The membrane potential and synaptic current represent the internal state variables of the LIF neuron, and they are updated at each time step based on the input and the previous state variables. \n",
    "\n",
    "These state variables are then used to determine whether the neuron should generate an output spike or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiking Graph Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify the Graph Convolution Layer:**\n",
    "\n",
    "The traditional GraphConvolution layer needs to be modified to handle spiking inputs and outputs. \n",
    "\n",
    "Instead of performing a single matrix multiplication, the spiking GraphConvolution layer will need to integrate the incoming spike trains and generate output spike trains based on the neuron dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SpikingGraphConvolution layer essentially performs a spiking version of the graph convolution operation, where information is propagated and integrated across the graph structure using spiking neuron dynamics instead of static activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingGraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SpikingGraphConvolution, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.reset_parameters()\n",
    "        self.neuron = LIFNeuron()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        self.neuron.set_batch_size(x.size(0))\n",
    "        # print(x.size(),self.weight.size(),adj.size())\n",
    "        support = torch.mm(x, self.weight)  # Linear transformation\n",
    "        output = torch.mm(adj, support)  # Graph convolution\n",
    "        mem, synaptic_current = self.neuron(output + self.bias)  # Spiking neuron\n",
    "        return mem, synaptic_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference from normal GC is in the last step, where instead of simply adding the bias and returning the output, the SpikingGraphConvolution layer uses a spiking neuron model (LIFNeuron) to integrate the propagated features (output + self.bias) over time.\n",
    "\n",
    "The LIFNeuron computes the membrane potential (mem) and synaptic current (synaptic_current) at each time step, based on the input and the previous state variables. These state variables represent the internal dynamics of the spiking neurons and determine whether the neurons should generate output spikes or not.\n",
    "\n",
    "By using spiking neuron dynamics, the SpikingGraphConvolution layer introduces temporal dynamics and models the information propagation using spike trains instead of static activations. This is more biologically plausible and potentially more efficient for certain types of tasks and hardware implementations.\n",
    "\n",
    "However, **the core idea of propagating and aggregating information across the graph structure remains the same**, with the **main difference being the use of spiking neuron dynamics instead of static activations** in the SpikingGraphConvolution layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikingGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SpikingGCN class defines the overall architecture of the Spiking Graph Convolutional Network (SGCN) model, consisting of two SpikingGraphConvolution layers and additional operations to handle spiking activations and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingGCN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        hidden_features,\n",
    "        out_features,\n",
    "        dropout,\n",
    "        time_window=100,\n",
    "    ):\n",
    "        super(SpikingGCN, self).__init__()\n",
    "        self.gc1 = SpikingGraphConvolution(in_features, hidden_features)\n",
    "        self.gc2 = SpikingGraphConvolution(hidden_features, out_features)\n",
    "        self.dropout = dropout\n",
    "        self.time_window = time_window  # Time window for spike counting (ms)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        mem1, synaptic_current1 = self.gc1(x, adj)\n",
    "        spike_rates1 = snn.synaptic_activation(synaptic_current1, self.time_window)\n",
    "        spike_rates1 = snn.spike_activation(snn.soft_spike(spike_rates1, self.dropout))\n",
    "\n",
    "        mem2, synaptic_current2 = self.gc2(spike_rates1, adj)\n",
    "        spike_rates2 = snn.synaptic_activation(synaptic_current2, self.time_window)\n",
    "        return spike_rates2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SpikingGCN model follows a similar structure to the traditional GCN, with two graph convolution layers separated by a non-linearity and dropout regularization. \n",
    "\n",
    "However, instead of using static activations, the SGCN model operates on spike trains and incorporates spiking neuron dynamics using the SpikingGraphConvolution layers and various spiking activation functions from the snntorch library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key steps in the forward pass are:\n",
    "\n",
    "1. Propagate and integrate the input spike trains through the first SpikingGraphConvolution layer to obtain the hidden layer's membrane potential and synaptic current.\n",
    "2. Convert the synaptic current to spike rates, apply a non-linearity and dropout regularization.\n",
    "3. Propagate and integrate the processed spike rates through the second SpikingGraphConvolution layer to obtain the output layer's membrane potential and synaptic current.\n",
    "4. Convert the output layer's synaptic current to spike rates, which represent the final output of the SGCN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual output of the model is a tensor of spike rates, representing the predicted output for each node in the graph.\n",
    "\n",
    "Specifically, the output of the `forward` method is `spike_rates2` : a tensor that contains the spike rates for each node and each output feature (or class) at the end of the simulation time window (`self.time_window`).\n",
    "\n",
    "The shape of `spike_rates2` would be `(num_nodes, out_features)`, where:\n",
    "\n",
    "- `num_nodes` is the number of nodes in the input graph.\n",
    "- `out_features` is the number of output features or classes, specified by the `out_features` parameter during the initialization of the `SpikingGCN` class.\n",
    "\n",
    "Each element `spike_rates2[i, j]` represents the spike rate (or firing rate) of node `i` for output feature (or class) `j` at the end of the simulation time window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of a classification task, **the spike rates can be interpreted as the predicted \"confidence\" or \"strength\" of each node belonging to each class**. Higher spike rates for a particular class would indicate a stronger prediction for that class.\n",
    "\n",
    "It's important to note that the spike rates are not necessarily bounded between 0 and 1, as they represent the firing rates of the spiking neurons over the simulation time window. However, you can apply a normalization or an activation function (e.g., softmax) to the spike rates to obtain class probabilities or a bounded output suitable for your specific task.\n",
    "\n",
    "For example, if you want to obtain class probabilities for a multi-class classification task, you could apply a softmax function to the spike rates:\n",
    "\n",
    "```python\n",
    "class_probabilities = nn.Softmax(dim=1)(spike_rates2)\n",
    "```\n",
    "\n",
    "Here `class_probabilities` would be a tensor of shape `(num_nodes, out_features)`, where each row sums to 1 and represents the probability distribution over the output classes for the corresponding node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data\n",
    "num_nodes = 10\n",
    "num_features = 5\n",
    "num_classes = 3\n",
    "time_window = 100\n",
    "\n",
    "# Node features\n",
    "node_features = torch.randn(num_nodes, num_features, time_window)\n",
    "\n",
    "# Adjacency matrix\n",
    "adj = torch.rand(num_nodes, num_nodes) < 0.2  # Random sparse adjacency matrix\n",
    "adj = adj.float()\n",
    "\n",
    "# Node labels (dummy data)\n",
    "node_labels = torch.randint(0, num_classes, (num_nodes,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import spikegen\n",
    "\n",
    "# Convert node features to spike trains\n",
    "node_features_spike = spikegen.rate(node_features, time_window)  # Shape: (num_nodes, num_features, time_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset and dataloader\n",
    "dataset = list(zip(node_features_spike, adj, node_labels))\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpikingGCN(\n",
    "    in_features=num_features,\n",
    "    hidden_features=8,\n",
    "    out_features=num_classes,\n",
    "    dropout=0.2,\n",
    "    time_window=time_window,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 5, 100]) torch.Size([5, 8]) torch.Size([2, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m features, adj_matrix, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape output for CrossEntropyLoss\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n",
      "File \u001b[0;32m~/repos/GU01-bioinspired-spatial-data/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/GU01-bioinspired-spatial-data/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[61], line 17\u001b[0m, in \u001b[0;36mSpikingGCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, adj):\n\u001b[0;32m---> 17\u001b[0m     mem1, synaptic_current1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     spike_rates1 \u001b[38;5;241m=\u001b[39m snn\u001b[38;5;241m.\u001b[39msynaptic_activation(synaptic_current1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_window)\n\u001b[1;32m     19\u001b[0m     spike_rates1 \u001b[38;5;241m=\u001b[39m snn\u001b[38;5;241m.\u001b[39mspike_activation(snn\u001b[38;5;241m.\u001b[39msoft_spike(spike_rates1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout))\n",
      "File \u001b[0;32m~/repos/GU01-bioinspired-spatial-data/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/GU01-bioinspired-spatial-data/.env/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[60], line 19\u001b[0m, in \u001b[0;36mSpikingGraphConvolution.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneuron\u001b[38;5;241m.\u001b[39mset_batch_size(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39msize(),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39msize(),adj\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m---> 19\u001b[0m support \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Linear transformation\u001b[39;00m\n\u001b[1;32m     20\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(adj, support)  \u001b[38;5;66;03m# Graph convolution\u001b[39;00m\n\u001b[1;32m     21\u001b[0m mem, synaptic_current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneuron(output \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)  \u001b[38;5;66;03m# Spiking neuron\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for features, adj_matrix, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features, adj_matrix)\n",
    "        output = output.permute(0, 2, 1)  # Reshape output for CrossEntropyLoss\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "###### print(x.size(),self.weight.size(),adj.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
